{"cells":[{"cell_type":"markdown","metadata":{"id":"aaAfLFKjLG2w"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mravanba/comp551-notebooks/blob/master/MLP.ipynb)\n","\n","# Multilayer Perceptron (MLP)\n","Our goal here is to implement a two-layer neural network for binary classification, train it using gradient descent and use it to classify the Iris dataset.\n","Our model is\n","$$\n","\\hat{y} = \\sigma \\left ( W \\sigma \\left ( V x \\right ) \\right)\n","$$\n","where we have $M$ hidden units and $D$ input features -- that is $w \\in \\mathbb{R}^{M}$, and $V \\in \\mathbb{R}^{M \\times D}$. For simplicity here we do not include a bias parameter for each layer. Key to our implementation is the gradient calculation. We follow the notation used in the slides here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1SqxPqxLG2_"},"outputs":[],"source":["import numpy as np\n","#%matplotlib notebook\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","from IPython.core.debugger import set_trace\n","from tensorflow import keras\n","import warnings\n","warnings.filterwarnings('ignore')\n","from sklearn.model_selection import KFold"]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"nPNwId5c2VO_"}},{"cell_type":"code","source":["# packaging it all into a function\n","def preprocess_fashion_mnist():\n","  import random as rand\n","   \n","   \n","  (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n","  # print(\"\\nx_train shape:\", x_train.shape, \" -- y_train shape\", y_train.shape)\n","  # print(\"x_test shape\", x_test.shape, \" -- y_test shape\", y_test.shape)\n","  mean_mat = np.mean(x_train, axis=0)\n","  # centering the data by removing the pixel wise mean from every pixel in every image\n","  x_train_centered = x_train - mean_mat\n","  x_test_centered = x_test - mean_mat\n","  # normalizing the grayscale values to values in interval [0,1]\n","  x_train_normalized = x_train_centered/255.0\n","  x_test_normalized = x_test_centered/255.0\n","\n","  #finally, flattening the data\n","  x_train = np.reshape(x_train_normalized, (60000,784))\n","  x_test = np.reshape(x_test_normalized, (10000, 784))\n","  #converting the test data to one hot encodings\n","  y_train = keras.utils.to_categorical(y_train, num_classes=10)\n","  y_test = keras.utils.to_categorical(y_test, num_classes=10)\n","  \n","  return x_train[:10000], y_train[:10000], x_test, y_test\n","x_train, y_train, x_test, y_test = preprocess_fashion_mnist()"],"metadata":{"id":"phWN5w-7GJOK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649008179561,"user_tz":240,"elapsed":1043,"user":{"displayName":"Seraphin Bassas","userId":"17841861031575039122"}},"outputId":"22153562-192b-45ec-ffbc-32eec7bfb796"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["# Model Implementation - SoftMax\n"],"metadata":{"id":"viQL0Q9L2dAM"}},{"cell_type":"markdown","source":["**Activation functions**"],"metadata":{"id":"oGwQgzDZ6XaO"}},{"cell_type":"code","source":["#activation functions\n","softmax1D = lambda z: np.exp(z)/float(sum(np.exp(z)))\n","softmax2D = lambda z: np.array([np.exp(i)/float(sum(np.exp(i))) for i in z])\n","\n","# Logistic\n","logistic = lambda z: 1./ (1 + np.exp(-z))\n","\n","# Tanh\n","tanh = lambda x: 2./ (1+np.exp(-2*x)) -1\n","tanh_grad = lambda x: 1 - np.square(2./ (1+np.exp(-2*x)) -1)\n","\n","# Leaky ReLu\n","def leaky_relu(x):\n","  alpha = 0.1\n","  x=np.array(x).astype(float)\n","  np.putmask(x, x<0, alpha*x)\n","  return x\n","\n","def leaky_relu_grad(x):\n","  alpha = 0.1\n","  x=np.array(x).astype(float)\n","  x[x>0]=1\n","  x[x<=0]=alpha\n","  return x\n","\n","  \n","# ReLu\n","def relu(x):\n","  x=np.array(x).astype(float)\n","  np.putmask(x, x<0, 0)\n","  return x\n","  \n","def relu_grad(x):\n","  x=np.array(x).astype(float)\n","  x[x>0]=1\n","  x[x<=0]=0\n","  return x"],"metadata":{"id":"dxQ35WhEQLdR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Accuracy function"],"metadata":{"id":"h524tYb46mwq"}},{"cell_type":"code","source":["def evaluate_acc(pred, truth):\n","  counter =0\n","  \n","  for i in range(len(pred)):\n","    maxVal = np.where(pred[i] == np.amax(pred[i]))\n","    counter += 1 if maxVal == np.where(truth[i]==1) else 0\n","  return counter * 100.0 / float(len(pred))\n","  "],"metadata":{"id":"hgeOx3cLuwEl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model - ReLu"],"metadata":{"id":"2sFWzkOs6pJ4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"a9CPhDEuLG3C"},"outputs":[],"source":["class MLPRelu:\n","    \n","    def __init__(self, M = 128, num_classes = 10):\n","        self.M = M\n","        self.num_classes = num_classes\n","        \n","            \n","    def fit(self, x, y, optimizer):\n","        N,D = x.shape\n","        def gradient(x, y, params):\n","            v1, v2, w = params # v1.shape = (D, M), v2.shape = (M, M) w.shape = (M)\n","            q1 = np.dot(x, v1) \n","            z1 = relu(q1) #N x M\n","            q2 = np.dot(z1, v2) # N\n","            z2 = relu(q2)\n","            yh = softmax2D(np.dot(z2, w))#N\n","            acc = evaluate_acc(yh,y)\n","            # print('yShape=', y.shape)\n","\n","            ## Backpropagation\n","            ## 1st layer\n","            dy = yh - y #N\n","            dw = np.dot(z2.T, dy)/N #M  \n","            ## 2nd Layer                  \n","            # dz = np.dot(dy.T, w)\n","            dz2 = np.dot(dy, w.numpy().T) #N x M                   = (yh-y)*w from slide 16\n","            dv2 = np.dot(z1.T, dz2 * relu_grad(q2))/N #D x M   = (yh-y)*w*(activation)'*x\n","            ## 3rd Layer\n","            dz1 = np.dot(dz2, v2.numpy().T) #N x M                   = (yh-y)*w from slide 16\n","            dv1 = np.dot(x.T, dz1 * relu_grad(q1))/N #D x M   = (yh-y)*w*(activation)'*x\n","            dparams = [dv1, dv2, dw]\n","            return dparams, acc\n","        \n","        # w = np.random.randn(self.M) * .01\n","        # v = np.random.randn(D,self.M) * .01\n","        initializer = keras.initializers.GlorotNormal()\n","        w = initializer(shape=(self.M, self.num_classes))\n","        v2 = initializer(shape=(self.M, self.M))\n","        v1 = initializer(shape=(D, self.M))\n","        \n","        params0 = [v1, v2,w]\n","        self.params, batch_acc = optimizer.run_mini_batch(gradient, x, y, params0)#optimizer.run_mini_batch(gradient, x, y, params0) #\n","        return self, batch_acc\n","    \n","    def predict(self, x):\n","        v1, v2, w = self.params\n","        z1 = relu(np.dot(x, v1)) #N x M\n","        z2 = relu(np.dot(z1, v2))\n","        yh = softmax2D(np.dot(z2, w))#N\n","        return yh"]},{"cell_type":"markdown","source":["# Model - Leaky ReLu"],"metadata":{"id":"Ay83GlgwGhfp"}},{"cell_type":"code","source":["class MLPLeakyRelu:\n","    \n","    def __init__(self, M = 128, num_classes = 10):\n","        self.M = M\n","        self.num_classes = num_classes\n","        \n","            \n","    def fit(self, x, y, optimizer):\n","        N,D = x.shape\n","        def gradient(x, y, params):\n","            # print('v1=',params[0].shape)\n","            # print('v2=',params[1].shape)\n","            # print('w=',params[2].shape)\n","            # print('x=',x.shape)\n","            v1, v2, w = params # v1.shape = (D, M), v2.shape = (M, M) w.shape = (M)\n","            q1 = np.dot(x, v1) \n","            z1 = leaky_relu(q1) #N x M\n","            # print('q1=',q1.shape)   \n","            # print('z1=',z1.shape)\n","\n","            q2 = np.dot(z1, v2) # N\n","            z2 = leaky_relu(q2)\n","            # print(\"z2=\", z2.shape)\n","\n","            # print(\"np.dot(z, w)=\",np.dot(z, w).shape)\n","            yh = softmax2D(np.dot(z2, w))#N\n","            # print(\"yhS=\",yh.shape)\n","            # print(\"yh=\", yh[:10,:])\n","            # #get accuracy based on predictions\n","            # print(evaluate_acc(yh,y))\n","            # print('yShape=', y.shape)\n","\n","            ## Backpropagation\n","            \n","            \n","\n","            ## 1st layer\n","            dy = yh - y #N\n","            dw = np.dot(z2.T, dy)/N #M  \n","            # print(\"dh=\",dy.shape)\n","            # print(\"dw=\", dw.shape)    # = (yh-y)*z\n","            \n","            \n","            ## 2nd Layer                  \n","            # dz = np.dot(dy.T, w)\n","            dz2 = np.dot(dy, w.numpy().T) #N x M                   = (yh-y)*w from slide 16\n","            \n","            #in the below line, dz * z * (1-v) is element wise operation, not matrix multiplication\n","            # temp = dz2 * relu_grad(q) #(1024,128) (32,128)\n","            dv2 = np.dot(z1.T, dz2 * leaky_relu_grad(q2))/N #D x M   = (yh-y)*w*(activation)'*x\n","            # print(\"dz2=\",dz2.shape)\n","            # print(\"dv2=\", dv2.shape)\n","\n","            ## 3rd Layer\n","            dz1 = np.dot(dz2, v2.numpy().T) #N x M                   = (yh-y)*w from slide 16\n","            dv1 = np.dot(x.T, dz1 * leaky_relu_grad(q1))/N #D x M   = (yh-y)*w*(activation)'*x\n","            # print(\"dz1=\",dz2.shape)\n","            # print(\"dv1=\", dv1.shape)\n","\n","\n","            dparams = [dv1, dv2, dw]\n","            # print(dparams)\n","            # print(\"yh shape:\",len(yh[0]))\n","            return dparams\n","        \n","        # w = np.random.randn(self.M) * .01\n","        # v = np.random.randn(D,self.M) * .01\n","        initializer = keras.initializers.GlorotNormal()\n","        w = initializer(shape=(self.M, self.num_classes))\n","        v2 = initializer(shape=(self.M, self.M))\n","        v1 = initializer(shape=(D, self.M))\n","        \n","        params0 = [v1, v2,w]\n","        self.params = optimizer.run_mini_batch(gradient, x, y, params0) #optimizer.run(gradient, x, y, params0)#\n","        return self\n","    \n","    def predict(self, x):\n","        v1, v2, w = self.params\n","        z1 = relu(np.dot(x, v1)) #N x M\n","        z2 = relu(np.dot(z1, v2))\n","        yh = softmax2D(np.dot(z2, w))#N\n","        return yh"],"metadata":{"id":"7tFk6kshGkQu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model - Tanh"],"metadata":{"id":"EzpLFltSCoBw"}},{"cell_type":"code","source":["class MLPTanh:\n","    \n","    def __init__(self, M = 128, num_classes = 10):\n","        self.M = M\n","        self.num_classes = num_classes\n","            \n","    def fit(self, x, y, optimizer):\n","        N,D = x.shape\n","        def gradient(x, y, params):\n","            # print('v1=',params[0].shape)\n","            # print('v2=',params[1].shape)\n","            # print('w=',params[2].shape)\n","            # print('x=',x.shape)\n","            v1, v2, w = params # v1.shape = (D, M), v2.shape = (M, M) w.shape = (M)\n","            q1 = np.dot(x, v1) \n","            z1 = tanh(q1) #N x M\n","            # print('q1=',q1.shape)   \n","            # print('z1=',z1.shape)\n","\n","            q2 = np.dot(z1, v2) # N\n","            z2 = tanh(q2)\n","            # print(\"z2=\", z2.shape)\n","\n","            # print(\"np.dot(z, w)=\",np.dot(z, w).shape)\n","            yh = softmax2D(np.dot(z2, w))#N\n","            # print(\"yhS=\",yh.shape)\n","            # print(\"yh=\", yh[:10,:])\n","            # #get accuracy based on predictions\n","            # print(evaluate_acc(yh,y))\n","            # print('yShape=', y.shape)\n","\n","            ## Backpropagation\n","            \n","            \n","\n","            ## 1st layer\n","            dy = yh - y #N\n","            dw = np.dot(z2.T, dy)/N #M  \n","            # print(\"dh=\",dy.shape)\n","            # print(\"dw=\", dw.shape)    # = (yh-y)*z\n","            \n","            \n","            ## 2nd Layer                  \n","            # dz = np.dot(dy.T, w)\n","            dz2 = np.dot(dy, w.numpy().T) #N x M                   = (yh-y)*w from slide 16\n","            \n","            #in the below line, dz * z * (1-v) is element wise operation, not matrix multiplication\n","            # temp = dz2 * relu_grad(q) #(1024,128) (32,128)\n","            dv2 = np.dot(z1.T, dz2 * tanh_grad(q2))/N #D x M   = (yh-y)*w*(activation)'*x\n","            # print(\"dz2=\",dz2.shape)\n","            # print(\"dv2=\", dv2.shape)\n","\n","            ## 3rd Layer\n","            dz1 = np.dot(dz2, v2.numpy().T) #N x M                   = (yh-y)*w from slide 16\n","            dv1 = np.dot(x.T, dz1 * tanh_grad(q1))/N #D x M   = (yh-y)*w*(activation)'*x\n","            # print(\"dz1=\",dz2.shape)\n","            # print(\"dv1=\", dv1.shape)\n","\n","\n","            dparams = [dv1, dv2, dw]\n","            # print(dparams)\n","            # print(\"yh shape:\",len(yh[0]))\n","            return dparams\n","        \n","        # w = np.random.randn(self.M) * .01\n","        # v = np.random.randn(D,self.M) * .01\n","        initializer = keras.initializers.GlorotNormal()\n","        w = initializer(shape=(self.M, self.num_classes))\n","        v2 = initializer(shape=(self.M, self.M))\n","        v1 = initializer(shape=(D, self.M))\n","        \n","        params0 = [v1, v2,w]\n","        self.params = optimizer.run_mini_batch(gradient, x, y, params0) #optimizer.run(gradient, x, y, params0)#\n","        return self\n","    \n","    def predict(self, x):\n","        v1, v2, w = self.params\n","        z1 = relu(np.dot(x, v1)) #N x M\n","        z2 = relu(np.dot(z1, v2))\n","        yh = softmax2D(np.dot(z2, w))#N\n","        return yh"],"metadata":{"id":"KPWIgv7eCqns"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Implementation - Logistic"],"metadata":{"id":"LnMuae8n2tsT"}},{"cell_type":"code","source":["q= (32, 128) # N x M\n","z= (32, 128) # N x M\n","yh= (32,) # N\n","dh= (32, 32) # N x N\n","dw= (128, 32) # M x N\n","dz= (1024, 128) # ? x M"],"metadata":{"id":"C3DRg3maWa7r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logistic = lambda z: 1./ (1 + np.exp(-z))\n","\n","class MLP_sig:\n","    \n","    def __init__(self, M = 64):\n","        self.M = M\n","            \n","    def fit(self, x, y, optimizer):\n","        N,D = x.shape\n","        def gradient(x, y, params):\n","            v, w = params\n","            z = logistic(np.dot(x, v)) #N x M\n","            yh = logistic(np.dot(z, w))#N\n","            # print(\"Train acc:\", evaluate_acc_sig(yh,y))\n","            dy = yh - y #N\n","            dw = np.dot(z.T, dy)/N #M\n","            dz = np.outer(dy, w) #N x M\n","            dv = np.dot(x.T, dz * z * (1 - z))/N #D x M\n","            dparams = [dv, dw]\n","            return dparams\n","        \n","        w = np.random.randn(self.M) * .01\n","        v = np.random.randn(D,self.M) * .01\n","        params0 = [v,w]\n","        self.params = optimizer.run_mini_batch(gradient, x, y, params0)\n","        return self\n","    \n","    def predict(self, x):\n","        v, w = self.params\n","        z = logistic(np.dot(x, v)) #N x M\n","        yh = logistic(np.dot(z, w))#N\n","        return yh\n","\n","def evaluate_acc_sig(yh,y):\n","  assert( len(yh) == len(y))\n","  counter =0\n","  for i in range(len(yh)):\n","    counter += 1 if yh[i] == y[i] else 0\n","  return counter * 100.0 / float(len(yh))"],"metadata":{"id":"E2anszpnoB0B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Batch Implementation"],"metadata":{"id":"o07x1kJe21uP"}},{"cell_type":"markdown","metadata":{"id":"WON0hiNiLG3E"},"source":["In the implementation above we have used a list data structure to maintain model parameters and their gradients. Below I have modified the `GradientDescent` class to also work with a list of parameters. One sournce of confusion in the above implementation is the gradient calculation. While in the slides during the lectures \n","we calculated the partial derivative for individual parameters, here, we use vector and matrix operations to calculate the derivative for *all* parameters. "]},{"cell_type":"code","source":["def mini_batcher(x, y, mini_batch_size):\n","  zipped = np.hstack( (x, y ) )\n","  np.random.shuffle(zipped)\n","  x_batches, y_batches = [], []\n","  mini_batches = []\n","  batch_num = x.shape[0] // mini_batch_size \n","  for i in range(batch_num):\n","    x_batch = zipped[ i * mini_batch_size : (i+1) * mini_batch_size, :-10]\n","    y_batch = zipped[ i * mini_batch_size : (i+1) * mini_batch_size, -10:]\n","    mini_batches.append( ( x_batch, y_batch) )\n","  if x.shape[0] % mini_batch_size != 0:\n","    x_batch = zipped[ batch_num * mini_batch_size :, :-10]\n","    y_batch = zipped[ batch_num * mini_batch_size :, -10:]\n","    mini_batches.append( ( x_batch, y_batch ) )\n","    \n","  return mini_batches"],"metadata":{"id":"edVLJC0tqSpA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gradient Descent \n","\n","---\n","\n"],"metadata":{"id":"rt5K2LpN3KcI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LRgwO0YHLG3E"},"outputs":[],"source":["class GradientDescent:\n","    \n","    def __init__(self, learning_rate=.002, max_iters=1000, epsilon=1e-4, batch_size=32):\n","        self.learning_rate = learning_rate\n","        self.max_iters = max_iters\n","        self.epsilon = epsilon\n","        \n","    def run(self, gradient_fn, x, y, params):\n","        norms = np.array([np.inf])\n","        t = 1\n","        while np.any(norms > self.epsilon) and t < self.max_iters:\n","            grad = gradient_fn(x, y, params)\n","            for p in range(len(params)):\n","                params[p] -= self.learning_rate * grad[p]\n","            t += 1\n","            norms = np.array([np.linalg.norm(g) for g in grad])\n","        print(t)\n","        return params\n","    \n","    \n","\n","    def run_mini_batch(self, gradient_fn, x, y, params, batch_size=32):\n","        norms = np.array([np.inf])\n","        t=1\n","        temp_acc,batch_acc, chunk= [], [], []\n","        mini_batches = mini_batcher(x, y, batch_size)\n","        # print(len(mini_batches))\n","        batch_index = 0\n","\n","        while np.any(norms > self.epsilon) and t < self.max_iters*len(mini_batches):\n","            \n","            if(batch_index == batch_size):\n","              mini_batches = mini_batcher(x, y, batch_size)\n","              batch_index = 0\n","            batch_index +=1\n","\n","            x_temp, y_temp = mini_batches[t % ( len(mini_batches)-1 ) ][0], mini_batches[t % ( len(mini_batches)-1 ) ][1]\n","            grad, temp_acc = gradient_fn(x_temp, y_temp, params)\n","            chunk.append(temp_acc)\n","            if t % 10000 == 0:\n","              print(f\"Epoch{t}:{temp_acc}%\")\n","            \n","            for p in range(len(params)):\n","                params[p] -= self.learning_rate * grad[p]\n","            if t%len(mini_batches) == 2:\n","              batch_acc.append(np.mean(chunk))\n","              chunk = []\n","            t += 1\n","            norms = np.array([np.linalg.norm(g) for g in grad])\n","        return params, batch_acc"]},{"cell_type":"markdown","source":["# MNIST DataSet"],"metadata":{"id":"Sx13m2QLRjZF"}},{"cell_type":"code","source":["model1 = MLPRelu(M=128, num_classes=10)\n","optimizer = GradientDescent(learning_rate=.002)\n","y_pred1, batch_acc = model1.fit(x_train[:10000], y_train[:10000], optimizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCMi5fHmFEfY","executionInfo":{"status":"ok","timestamp":1649016794397,"user_tz":240,"elapsed":1376162,"user":{"displayName":"Seraphin Bassas","userId":"17841861031575039122"}},"outputId":"0a54966a-6a5b-459a-a17b-5dd7ab688bc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch10000:21.875%\n","Epoch20000:25.0%\n","Epoch30000:28.125%\n","Epoch40000:37.5%\n","Epoch50000:34.375%\n","Epoch60000:43.75%\n","Epoch70000:37.5%\n","Epoch80000:40.625%\n","Epoch90000:46.875%\n","Epoch100000:62.5%\n","Epoch110000:46.875%\n","Epoch120000:50.0%\n","Epoch130000:59.375%\n","Epoch140000:53.125%\n","Epoch150000:56.25%\n","Epoch160000:59.375%\n","Epoch170000:65.625%\n","Epoch180000:75.0%\n","Epoch190000:53.125%\n","Epoch200000:53.125%\n","Epoch210000:78.125%\n","Epoch220000:62.5%\n","Epoch230000:68.75%\n","Epoch240000:75.0%\n","Epoch250000:59.375%\n","Epoch260000:65.625%\n","Epoch270000:81.25%\n","Epoch280000:62.5%\n","Epoch290000:68.75%\n","Epoch300000:71.875%\n","Epoch310000:65.625%\n"]}]},{"cell_type":"code","source":["y_test_pred1 = model1.predict(x_test)\n","\n","print(\"Number of full training batch iterations:\",len(batch_acc))\n","print(\"Accuracies per training batch:\")\n","for i in batch_acc:\n","  print(i)\n","print(\"---------\")\n","fig, ax = plt.subplots()\n","ax.scatter(range(len(batch_acc)), batch_acc, c='r', marker='x')\n","ax.legend()\n","ax.grid(True)\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.show()\n","print(evaluate_acc(y_test_pred1, y_test))"],"metadata":{"id":"h_yOflLSFKXU","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1649016795477,"user_tz":240,"elapsed":579,"user":{"displayName":"Seraphin Bassas","userId":"17841861031575039122"}},"outputId":"23c88058-3369-45cf-845c-d3240cd5c3b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["No handles with labels found to put in legend.\n"]},{"output_type":"stream","name":"stdout","text":["Number of full training batch iterations: 1000\n","Accuracies per training batch:\n","6.25\n","7.118610223642173\n","7.527955271565495\n","6.928913738019169\n","7.577875399361022\n","7.617811501597444\n","7.75758785942492\n","8.446485623003195\n","8.496405750798722\n","8.905750798722044\n","9.205271565495208\n","9.544728434504792\n","9.48482428115016\n","9.914137380191693\n","10.083865814696486\n","9.9241214057508\n","10.782747603833865\n","10.363418530351439\n","11.601437699680512\n","11.421725239616613\n","11.601437699680512\n","11.940894568690096\n","12.010782747603834\n","11.441693290734824\n","12.210463258785943\n","12.26038338658147\n","13.588258785942491\n","13.498402555910543\n","13.728035143769969\n","13.757987220447284\n","13.76797124600639\n","14.13738019169329\n","14.83626198083067\n","14.936102236421725\n","14.886182108626198\n","15.64496805111821\n","15.944488817891374\n","15.545127795527156\n","16.234025559105433\n","16.21405750798722\n","17.20247603833866\n","16.333865814696484\n","17.392172523961662\n","18.2008785942492\n","17.781549520766774\n","18.62020766773163\n","18.89976038338658\n","18.96964856230032\n","19.788338658146966\n","19.728434504792332\n","19.548722044728436\n","19.6685303514377\n","20.686900958466452\n","19.968051118210862\n","21.775159744408946\n","20.277555910543132\n","20.836661341853034\n","21.265974440894567\n","20.84664536741214\n","22.46405750798722\n","21.63538338658147\n","22.034744408945688\n","22.763578274760384\n","23.123003194888177\n","22.803514376996805\n","23.432507987220447\n","23.332667731629392\n","24.031549520766774\n","23.891773162939298\n","23.86182108626198\n","23.86182108626198\n","24.390974440894567\n","24.61062300319489\n","24.470846645367413\n","24.770367412140576\n","24.510782747603834\n","25.34944089456869\n","25.778753993610223\n","26.06829073482428\n","25.299520766773163\n","25.968450479233226\n","26.19808306709265\n","26.33785942492013\n","26.54752396166134\n","26.78714057507987\n","26.81709265175719\n","25.9185303514377\n","26.277955271565496\n","26.517571884984026\n","26.597444089456868\n","27.18650159744409\n","27.18650159744409\n","27.855431309904155\n","27.53594249201278\n","27.216453674121407\n","27.236421725239616\n","28.354632587859424\n","27.655750798722046\n","27.955271565495206\n","28.075079872204473\n","28.6741214057508\n","28.923722044728436\n","28.58426517571885\n","28.444488817891372\n","29.163338658146966\n","29.313099041533548\n","29.013578274760384\n","29.08346645367412\n","29.602635782747605\n","29.093450479233226\n","29.363019169329075\n","30.041932907348244\n","29.642571884984026\n","29.892172523961662\n","30.02196485623003\n","29.952076677316295\n","30.26158146964856\n","30.35143769968051\n","30.960463258785943\n","30.59105431309904\n","30.521166134185304\n","30.760782747603834\n","30.890575079872203\n","30.94049520766773\n","31.28993610223642\n","30.92052715654952\n","31.309904153354633\n","31.240015974440894\n","31.31988817891374\n","31.230031948881788\n","32.198482428115014\n","31.779153354632587\n","31.110223642172524\n","31.75918530351438\n","31.72923322683706\n","31.44968051118211\n","31.809105431309906\n","31.439696485623003\n","31.99880191693291\n","32.84744408945687\n","32.138578274760384\n","33.097044728434504\n","33.13698083067093\n","32.45806709265176\n","33.316693290734825\n","32.727635782747605\n","32.68769968051118\n","33.6461661341853\n","33.53634185303515\n","33.72603833865815\n","34.384984025559106\n","33.24680511182109\n","33.59624600638978\n","33.995607028753994\n","33.316693290734825\n","34.31509584664537\n","34.98402555910543\n","34.76437699680511\n","34.43490415335463\n","33.2767571884984\n","34.31509584664537\n","34.12539936102237\n","34.564696485623\n","34.67452076677316\n","34.67452076677316\n","35.912539936102235\n","35.04392971246006\n","35.41333865814696\n","35.44329073482428\n","36.09225239616613\n","35.08386581469649\n","35.89257188498402\n","35.173722044728436\n","35.173722044728436\n","35.56309904153355\n","35.852635782747605\n","36.01238019169329\n","35.88258785942492\n","35.49321086261981\n","36.48162939297124\n","36.12220447284345\n","36.91094249201278\n","36.85103833865815\n","36.85103833865815\n","36.74121405750799\n","37.20047923322684\n","37.06070287539936\n","37.569888178913736\n","37.290335463258785\n","37.62979233226837\n","37.28035143769968\n","37.340255591054316\n","37.8694089456869\n","37.52995207667732\n","36.80111821086262\n","36.88099041533546\n","37.66972843450479\n","37.89936102236422\n","37.42012779552716\n","38.10902555910543\n","38.2288338658147\n","38.388578274760384\n","37.82947284345048\n","39.8961661341853\n","38.298722044728436\n","38.39856230031949\n","38.89776357827476\n","39.50678913738019\n","39.037539936102235\n","39.24720447284345\n","39.37699680511182\n","38.48841853035144\n","39.26717252396166\n","38.93769968051118\n","38.64816293929712\n","40.09584664536741\n","40.0658945686901\n","39.96605431309904\n","39.456869009584665\n","40.49520766773163\n","40.724840255591054\n","39.676517571884986\n","40.22563897763578\n","40.03594249201278\n","40.105830670926515\n","40.84464856230032\n","40.18570287539936\n","40.31549520766773\n","40.29552715654952\n","41.63338658146965\n","41.5435303514377\n","41.3538338658147\n","41.144169329073485\n","41.343849840255594\n","41.483626198083066\n","41.40375399361022\n","41.33386581469649\n","42.551916932907346\n","42.08266773162939\n","42.93130990415335\n","42.382188498402556\n","42.00279552715655\n","42.4620607028754\n","42.20247603833866\n","42.49201277955272\n","42.74161341853035\n","43.18091054313099\n","43.111022364217256\n","43.14097444089457\n","41.92292332268371\n","43.25079872204473\n","43.22084664536741\n","44.09944089456869\n","43.1908945686901\n","43.510383386581466\n","43.680111821086264\n","42.691693290734825\n","43.260782747603834\n","43.46046325878594\n","44.129392971246006\n","43.63019169329073\n","44.069488817891376\n","44.33905750798722\n","43.5702875399361\n","43.42052715654952\n","45.427316293929714\n","44.81829073482428\n","44.53873801916933\n","44.53873801916933\n","45.54712460063898\n","44.019568690095845\n","45.25758785942492\n","45.00798722044728\n","45.29752396166134\n","44.03953674121406\n","45.29752396166134\n","44.73841853035144\n","45.89656549520767\n","45.72683706070288\n","45.74680511182109\n","46.00638977635783\n","46.85503194888179\n","45.766773162939295\n","44.82827476038339\n","45.9564696485623\n","45.62699680511182\n","46.27595846645367\n","45.5870607028754\n","46.325878594249204\n","45.646964856230035\n","46.236022364217256\n","46.39576677316294\n","45.34744408945687\n","46.54552715654952\n","47.364217252396166\n","47.27436102236422\n","47.344249201277954\n","46.90495207667732\n","46.775159744408946\n","47.40415335463259\n","47.10463258785943\n","47.783546325878596\n","47.8035143769968\n","48.182907348242814\n","46.59544728434505\n","46.43570287539936\n","47.49400958466454\n","47.96325878594249\n","48.44249201277955\n","48.37260383386582\n","47.873402555910545\n","47.254392971246006\n","48.49241214057508\n","47.53394568690096\n","47.673722044728436\n","49.16134185303515\n","48.79193290734824\n","49.0814696485623\n","48.891773162939295\n","48.92172523961661\n","48.81190095846645\n","48.99161341853035\n","48.7120607028754\n","48.5323482428115\n","49.680511182108624\n","49.64057507987221\n","48.64217252396166\n","49.8202875399361\n","48.65215654952077\n","49.47084664536741\n","49.570686900958464\n","49.78035143769968\n","49.40095846645367\n","48.831869009584665\n","48.771964856230035\n","50.25958466453674\n","49.69049520766773\n","50.07987220447284\n","49.47084664536741\n","50.069888178913736\n","50.05990415335463\n","50.688897763578275\n","50.628993610223645\n","50.888578274760384\n","50.59904153354633\n","50.009984025559106\n","49.950079872204476\n","51.26797124600639\n","50.75878594249201\n","50.1797124600639\n","50.748801916932905\n","50.45926517571885\n","51.04832268370607\n","49.64057507987221\n","50.828674121405754\n","51.72723642172524\n","50.9285143769968\n","51.00838658146965\n","51.68730031948882\n","51.66733226837061\n","52.08666134185304\n","50.888578274760384\n","51.787140575079874\n","51.98682108626198\n","51.72723642172524\n","52.436102236421725\n","52.096645367412144\n","52.216453674121404\n","52.10662939297124\n","52.326277955271564\n","51.427715654952074\n","52.9452875399361\n","52.30630990415335\n","51.94688498402556\n","53.314696485623\n","52.266373801916934\n","52.34624600638978\n","51.50758785942492\n","52.89536741214057\n","52.745607028753994\n","53.27476038338658\n","52.99520766773163\n","52.096645367412144\n","53.01517571884984\n","52.575878594249204\n","53.394568690095845\n","53.65415335463259\n","53.25479233226837\n","53.90375399361022\n","53.21485623003195\n","54.2232428115016\n","53.843849840255594\n","53.78394568690096\n","53.6841054313099\n","53.73402555910543\n","53.8538338658147\n","53.54432907348243\n","54.75239616613418\n","54.69249201277955\n","54.67252396166134\n","53.15495207667732\n","53.73402555910543\n","54.08346645367412\n","54.28314696485623\n","55.57108626198083\n","55.21166134185304\n","54.93210862619808\n","54.462859424920126\n","55.051916932907346\n","55.44129392971246\n","56.060303514377\n","56.16014376996805\n","55.17172523961661\n","54.462859424920126\n","55.27156549520767\n","55.421325878594246\n","55.65095846645367\n","55.04193290734824\n","55.47124600638978\n","55.68091054313099\n","55.43130990415335\n","56.0702875399361\n","56.17012779552716\n","56.17012779552716\n","56.22004792332268\n","55.870607028753994\n","56.210063897763575\n","56.010383386581466\n","55.86062300319489\n","56.659345047923324\n","56.90894568690096\n","56.210063897763575\n","56.679313099041536\n","56.289936102236425\n","57.25838658146965\n","57.31829073482428\n","56.47963258785943\n","56.41972843450479\n","56.888977635782744\n","56.35982428115016\n","56.63937699680511\n","57.248402555910545\n","57.80750798722045\n","57.39816293929712\n","57.138578274760384\n","56.72923322683706\n","57.64776357827476\n","57.65774760383387\n","58.11701277955272\n","57.727635782747605\n","57.138578274760384\n","57.697683706070286\n","58.10702875399361\n","57.837460063897765\n","57.76757188498402\n","58.346645367412144\n","58.13698083067093\n","57.66773162939297\n","58.19688498402556\n","58.69608626198083\n","58.47643769968051\n","58.02715654952077\n","57.63777955271566\n","58.39656549520767\n","58.35662939297124\n","58.61621405750799\n","58.86581469648562\n","58.8158945686901\n","58.546325878594246\n","58.56629392971246\n","58.656150159744406\n","58.47643769968051\n","59.06549520766773\n","58.56629392971246\n","58.98562300319489\n","59.26517571884984\n","58.70607028753994\n","59.11541533546326\n","58.91573482428115\n","59.68450479233227\n","59.66453674121406\n","60.14376996805112\n","59.06549520766773\n","59.67452076677316\n","59.48482428115016\n","60.263578274760384\n","59.614616613418534\n","59.29512779552716\n","60.18370607028754\n","60.003993610223645\n","60.44329073482428\n","59.91413738019169\n","60.2935303514377\n","59.894169329073485\n","59.90415335463259\n","60.13378594249201\n","59.88418530351438\n","60.1038338658147\n","59.844249201277954\n","59.7444089456869\n","59.784345047923324\n","60.73282747603834\n","60.87260383386582\n","60.433306709265175\n","59.94408945686901\n","61.20207667731629\n","61.14217252396166\n","60.50319488817891\n","60.593051118210866\n","60.2935303514377\n","60.123801916932905\n","61.01238019169329\n","60.55311501597444\n","60.92252396166134\n","60.98242811501598\n","60.62300319488818\n","60.852635782747605\n","61.641373801916934\n","60.1038338658147\n","60.89257188498402\n","60.742811501597444\n","61.281948881789134\n","61.60143769968051\n","61.66134185303515\n","61.591453674121404\n","61.751198083067095\n","61.192092651757186\n","61.48162939297124\n","61.01238019169329\n","61.69129392971246\n","61.950878594249204\n","61.66134185303515\n","62.28035143769968\n","60.95247603833866\n","61.5714856230032\n","61.42172523961661\n","61.611421725239616\n","61.18210862619808\n","61.391773162939295\n","61.35183706070288\n","61.41174121405751\n","62.60982428115016\n","61.68130990415335\n","62.28035143769968\n","62.030750798722046\n","61.271964856230035\n","61.9408945686901\n","61.88099041533546\n","62.14057507987221\n","62.05071884984026\n","62.60982428115016\n","61.9408945686901\n","62.010782747603834\n","61.99081469648562\n","61.611421725239616\n","61.32188498402556\n","61.84105431309904\n","61.52156549520767\n","61.671325878594246\n","61.751198083067095\n","62.27036741214057\n","62.14057507987221\n","60.92252396166134\n","62.95926517571885\n","62.290335463258785\n","62.66972843450479\n","62.19049520766773\n","62.3202875399361\n","62.48003194888179\n","61.950878594249204\n","62.450079872204476\n","63.27875399361022\n","61.68130990415335\n","62.230431309904155\n","61.56150159744409\n","63.10902555910543\n","62.14057507987221\n","62.24041533546326\n","62.25039936102237\n","62.5\n","62.47004792332268\n","61.88099041533546\n","61.51158146964856\n","62.60982428115016\n","63.019169329073485\n","62.30031948881789\n","63.14896166134185\n","62.94928115015974\n","62.62979233226837\n","63.30870607028754\n","63.87779552715655\n","63.20886581469649\n","64.03753993610223\n","63.7879392971246\n","63.049121405750796\n","62.879392971246006\n","62.22044728434505\n","62.689696485623\n","62.38019169329073\n","63.4285143769968\n","63.448482428115014\n","64.09744408945687\n","62.88937699680511\n","62.74960063897763\n","63.74800319488818\n","64.39696485623003\n","63.58825878594249\n","63.9676517571885\n","63.74800319488818\n","62.41014376996805\n","63.89776357827476\n","63.049121405750796\n","63.20886581469649\n","63.84784345047923\n","63.947683706070286\n","62.6797124600639\n","64.49680511182109\n","62.689696485623\n","63.28873801916933\n","64.23722044728434\n","63.61821086261981\n","64.03753993610223\n","63.85782747603834\n","63.39856230031949\n","64.6964856230032\n","63.33865814696485\n","63.45846645367412\n","63.837859424920126\n","64.37699680511182\n","63.56829073482428\n","63.47843450479233\n","63.89776357827476\n","63.558306709265175\n","63.0591054313099\n","63.47843450479233\n","63.528354632587856\n","63.448482428115014\n","64.1373801916933\n","64.07747603833866\n","63.328674121405754\n","63.02915335463259\n","64.94608626198082\n","64.72643769968052\n","63.079073482428115\n","64.1473642172524\n","65.0658945686901\n","63.25878594249201\n","63.807907348242814\n","64.3270766773163\n","64.20726837060703\n","63.93769968051118\n","63.90774760383387\n","64.23722044728434\n","64.78634185303514\n","63.63817891373802\n","63.84784345047923\n","63.85782747603834\n","63.93769968051118\n","63.91773162939297\n","63.698083067092654\n","63.76797124600639\n","64.63658146964856\n","64.54672523961662\n","64.56669329073482\n","64.04752396166134\n","64.46685303514377\n","64.31709265175719\n","64.5067891373802\n","63.99760383386582\n","64.44688498402556\n","64.3270766773163\n","65.35543130990415\n","64.59664536741214\n","64.78634185303514\n","65.435303514377\n","65.48522364217253\n","64.92611821086263\n","64.44688498402556\n","65.11581469648563\n","64.80630990415335\n","65.20567092651757\n","64.47683706070288\n","64.48682108626198\n","65.32547923322684\n","64.43690095846645\n","64.94608626198082\n","64.36701277955271\n","64.78634185303514\n","64.5167731629393\n","65.41533546325878\n","65.20567092651757\n","64.83626198083067\n","65.27555910543131\n","64.64656549520767\n","65.20567092651757\n","64.93610223642173\n","64.39696485623003\n","65.625\n","65.10583067092652\n","65.32547923322684\n","65.33546325878594\n","65.22563897763578\n","65.52515974440895\n","65.58506389776358\n","65.04592651757189\n","66.08426517571885\n","65.82468051118211\n","65.16573482428115\n","65.93450479233226\n","65.88458466453675\n","64.8761980830671\n","64.65654952076677\n","64.84624600638978\n","65.38538338658147\n","65.64496805111821\n","64.93610223642173\n","64.84624600638978\n","65.0758785942492\n","65.31549520766774\n","65.18570287539936\n","64.97603833865814\n","65.52515974440895\n","65.0758785942492\n","65.8047124600639\n","65.48522364217253\n","65.83466453674122\n","65.65495207667732\n","64.64656549520767\n","64.95607028753993\n","64.54672523961662\n","65.60503194888179\n","65.75479233226837\n","65.58506389776358\n","65.14576677316293\n","65.814696485623\n","66.07428115015975\n","65.49520766773163\n","65.97444089456869\n","65.57507987220447\n","66.04432907348243\n","65.57507987220447\n","65.52515974440895\n","65.6150159744409\n","65.57507987220447\n","65.30551118210863\n","65.14576677316293\n","65.77476038338658\n","65.49520766773163\n","65.42531948881789\n","66.33386581469648\n","65.66493610223642\n","65.29552715654953\n","66.65335463258786\n","65.9944089456869\n","66.44369009584665\n","65.87460063897764\n","66.02436102236422\n","66.42372204472844\n","65.71485623003196\n","65.95447284345047\n","65.76477635782747\n","65.70487220447285\n","66.16413738019169\n","66.32388178913737\n","65.08586261980831\n","66.38378594249201\n","66.33386581469648\n","66.13418530351437\n","65.47523961661342\n","66.95287539936102\n","66.27396166134186\n","65.96445686900958\n","66.52356230031948\n","65.71485623003196\n","66.26397763578275\n","66.05431309904154\n","66.59345047923323\n","66.43370607028754\n","65.82468051118211\n","66.26397763578275\n","65.86461661341853\n","65.72484025559105\n","66.60343450479233\n","66.26397763578275\n","66.59345047923323\n","66.77316293929712\n","66.33386581469648\n","66.88298722044729\n","66.56349840255591\n","66.40375399361022\n","66.9229233226837\n","66.45367412140575\n","66.39376996805112\n","66.86301916932908\n","65.65495207667732\n","66.20407348242811\n","66.21405750798722\n","66.16413738019169\n","66.57348242811501\n","66.84305111821087\n","66.1741214057508\n","67.44209265175719\n","66.09424920127796\n","66.87300319488818\n","66.63338658146965\n","67.09265175718849\n","67.49201277955271\n","66.93290734824281\n","66.84305111821087\n","65.97444089456869\n","65.77476038338658\n","66.70327476038338\n","66.80311501597444\n","66.86301916932908\n","66.79313099041534\n","65.77476038338658\n","66.5435303514377\n","66.3738019169329\n","66.77316293929712\n","66.69329073482429\n","66.5435303514377\n","66.29392971246007\n","67.13258785942492\n","67.01277955271566\n","67.49201277955271\n","66.59345047923323\n","66.64337060702876\n","66.7432108626198\n","66.53354632587859\n","66.53354632587859\n","67.03274760383387\n","67.16253993610223\n","68.04113418530352\n","66.77316293929712\n","66.56349840255591\n","67.06269968051119\n","65.65495207667732\n","66.76317891373802\n","66.83306709265176\n","67.2723642172524\n","67.35223642172524\n","67.05271565495208\n","66.60343450479233\n","67.40215654952077\n","66.44369009584665\n","66.56349840255591\n","67.35223642172524\n","66.12420127795527\n","67.17252396166134\n","66.31389776357827\n","67.16253993610223\n","66.53354632587859\n","67.12260383386581\n","66.57348242811501\n","66.72324281150159\n","67.4520766773163\n","66.29392971246007\n","67.73162939297124\n","66.21405750798722\n","66.59345047923323\n","67.61182108626198\n","66.15415335463258\n","67.20247603833866\n","67.23242811501598\n","66.45367412140575\n","66.83306709265176\n","67.78154952076677\n","67.88138977635782\n","67.95127795527156\n","66.83306709265176\n","67.52196485623003\n","68.31070287539936\n","67.21246006389777\n","67.20247603833866\n","67.20247603833866\n","66.87300319488818\n","66.75319488817891\n","67.71166134185303\n","67.13258785942492\n","68.02116613418531\n","67.4520766773163\n","67.69169329073482\n","67.20247603833866\n","67.01277955271566\n","67.1126198083067\n","66.44369009584665\n","66.78314696485623\n","66.43370607028754\n","67.1026357827476\n","67.14257188498402\n","67.87140575079871\n","66.82308306709265\n","67.77156549520767\n","67.42212460063898\n","66.98282747603834\n","67.09265175718849\n","67.36222044728434\n","67.20247603833866\n","68.06110223642173\n","67.50199680511182\n","66.1741214057508\n","67.58186900958466\n","67.65175718849841\n","67.43210862619809\n","67.0726837060703\n","67.05271565495208\n","67.57188498402556\n","66.93290734824281\n","66.47364217252397\n","67.72164536741214\n","67.59185303514377\n","67.00279552715655\n","66.67332268370608\n","67.61182108626198\n","67.43210862619809\n","67.97124600638978\n","67.41214057507987\n","67.62180511182109\n","67.84145367412141\n","67.6317891373802\n","67.33226837060703\n","67.2923322683706\n","67.01277955271566\n","67.34225239616613\n","67.02276357827476\n","68.04113418530352\n","67.25239616613419\n","67.35223642172524\n","67.34225239616613\n","67.28234824281151\n","67.61182108626198\n","66.20407348242811\n","67.79153354632588\n","67.71166134185303\n","67.36222044728434\n","67.6317891373802\n","67.2923322683706\n","66.90295527156549\n","67.60183706070288\n","67.93130990415335\n","67.72164536741214\n","68.27076677316293\n","67.49201277955271\n","67.99121405750799\n","67.79153354632588\n","67.12260383386581\n","66.68330670926518\n","67.2723642172524\n","67.87140575079871\n","67.14257188498402\n","67.22244408945687\n","67.55191693290735\n","68.02116613418531\n","67.96126198083067\n","68.50039936102236\n","66.9229233226837\n","67.54193290734824\n","67.73162939297124\n","68.09105431309904\n","67.36222044728434\n","68.64017571884985\n","67.75159744408946\n","68.21086261980831\n","68.23083067092652\n","66.72324281150159\n","67.70167731629392\n","67.79153354632588\n","67.05271565495208\n","68.42052715654953\n","68.0011980830671\n","67.52196485623003\n","67.59185303514377\n","68.23083067092652\n","68.32068690095846\n","68.17092651757189\n","68.45047923322684\n","68.52036741214057\n","68.21086261980831\n","67.87140575079871\n","68.95966453674122\n","67.93130990415335\n","67.17252396166134\n","68.25079872204473\n","68.60023961661342\n","67.00279552715655\n","67.69169329073482\n","67.92132587859425\n","68.0111821086262\n","67.4520766773163\n","67.93130990415335\n","68.26078274760384\n","68.15095846645367\n","68.43051118210863\n","68.14097444089457\n","68.87979233226837\n","67.92132587859425\n","68.44049520766774\n","67.99121405750799\n","68.18091054313099\n","67.81150159744409\n","---------\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["68.04\n"]}]},{"cell_type":"code","source":["evaluate_acc(y_test_pred1, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"thi4rHRsFKIo","executionInfo":{"status":"ok","timestamp":1649017209692,"user_tz":240,"elapsed":291,"user":{"displayName":"Seraphin Bassas","userId":"17841861031575039122"}},"outputId":"5e8e4617-48ba-45ec-c342-41aae86988e3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["68.04"]},"metadata":{},"execution_count":26}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"colab":{"name":"3LayerMLP.ipynb","provenance":[{"file_id":"1AE_3CunEj0UW8eQz2bH_Vh7m5QBrldPI","timestamp":1648694691980}],"collapsed_sections":["aaAfLFKjLG2w","nPNwId5c2VO_","Ay83GlgwGhfp","EzpLFltSCoBw","LnMuae8n2tsT","o07x1kJe21uP"]}},"nbformat":4,"nbformat_minor":0}